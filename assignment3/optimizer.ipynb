{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f69ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 169\n",
      "Confidence Score: 1.1527\n",
      "Params (Dist, Prom, Smooth): (np.int64(20), 0.01, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from skimage.filters import sobel\n",
    "\n",
    "def load_and_preprocess(path):\n",
    "    try:\n",
    "        # Standard .img (ENVI/Flat) loading\n",
    "        img_data = np.fromfile(path, dtype=np.uint8)\n",
    "        # Assuming 512x512 based on your previous logic\n",
    "        # If there is a header, we slice the first 512 bytes\n",
    "        return img_data[512:].reshape((512, 512))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Core Peakiness Threshold\n",
    "# ------------------------------------------------------------\n",
    "def threshold_peakiness_advanced(smoothed_hist, min_distance, prominence_thresh):\n",
    "    \"\"\"Operates on a pre-smoothed histogram for speed.\"\"\"\n",
    "    # Vectorized peak detection\n",
    "    peaks = np.where(\n",
    "        (smoothed_hist[1:-1] > smoothed_hist[:-2]) &\n",
    "        (smoothed_hist[1:-1] > smoothed_hist[2:]) &\n",
    "        (smoothed_hist[1:-1] > prominence_thresh)\n",
    "    )[0] + 1\n",
    "\n",
    "    best_score = -1\n",
    "    best_valley = 127 # Default mid-point\n",
    "\n",
    "    for i, j in itertools.combinations(range(len(peaks)), 2):\n",
    "        p1, p2 = peaks[i], peaks[j]\n",
    "        if abs(p1 - p2) < min_distance:\n",
    "            continue\n",
    "\n",
    "        valley_region = smoothed_hist[p1:p2+1]\n",
    "        valley_idx = p1 + np.argmin(valley_region)\n",
    "        valley_height = smoothed_hist[valley_idx]\n",
    "        \n",
    "        # Peakiness: Ratio of the shorter peak to the valley floor\n",
    "        peakiness = min(smoothed_hist[p1], smoothed_hist[p2]) / (valley_height + 1e-6)\n",
    "\n",
    "        if peakiness > best_score:\n",
    "            best_score = peakiness\n",
    "            best_valley = valley_idx\n",
    "\n",
    "    return best_valley, best_score\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Optimized Objective Function\n",
    "# ------------------------------------------------------------\n",
    "def segmentation_score(image, binary, threshold, peakiness_score, edges, hist):\n",
    "    \"\"\"Uses pre-calculated edges and hist to save CPU cycles.\"\"\"\n",
    "    \n",
    "    # 1. Normalized Between-class variance (Otsu)\n",
    "    # Range scaled to [0, 1]\n",
    "    prob = hist / hist.sum()\n",
    "    w0 = prob[:threshold].sum()\n",
    "    w1 = prob[threshold:].sum()\n",
    "    \n",
    "    if w0 == 0 or w1 == 0:\n",
    "        return -1\n",
    "\n",
    "    mu0 = np.sum(np.arange(threshold) * prob[:threshold]) / w0\n",
    "    mu1 = np.sum(np.arange(threshold, 256) * prob[threshold:]) / w1\n",
    "    bcv = w0 * w1 * (mu0 - mu1) ** 2\n",
    "    # Empirical normalization for BCV (max possible for 8-bit is ~16384)\n",
    "    norm_bcv = bcv / 4000 \n",
    "\n",
    "    # 2. Edge Alignment\n",
    "    # Measures how well the binary boundary aligns with high-gradient areas\n",
    "    edge_mask = cv2.dilate(binary, np.ones((3,3))) - cv2.erode(binary, np.ones((3,3)))\n",
    "    edge_alignment = np.mean(edges[edge_mask > 0]) if np.any(edge_mask) else 0\n",
    "\n",
    "    # 3. Fast Noise Penalty \n",
    "    # Instead of label(), use opening to see how many pixels are 'lost' (noise)\n",
    "    opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((3,3)))\n",
    "    noise_ratio = np.sum(binary != opened) / binary.size\n",
    "\n",
    "    # Composite score with weighted components\n",
    "    # Weights: Otsu (40%), Peakiness (30%), Edges (20%), Noise Penalty (10%)\n",
    "    score = (0.4 * norm_bcv) + (0.3 * peakiness_score) + (0.2 * edge_alignment) - (0.1 * noise_ratio)\n",
    "    return score\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Parameter Optimizer\n",
    "# ------------------------------------------------------------\n",
    "def optimize_segmentation(image):\n",
    "    # PRE-CALCULATE static data\n",
    "    edges = sobel(image)\n",
    "    hist = np.bincount(image.ravel(), minlength=256).astype(np.float64)\n",
    "    std_val = np.std(image)\n",
    "\n",
    "    # Search ranges\n",
    "    min_dist_range = np.linspace(0.3 * std_val, 0.7 * std_val, 5).astype(int)\n",
    "    prominence_range = [0.01, 0.05, 0.1]\n",
    "    smooth_range = [1.0, 2.0, 3.0]\n",
    "\n",
    "    best_global_score = -np.inf\n",
    "    best_results = {}\n",
    "\n",
    "    # Pre-calculate smoothed histograms to avoid repeating in the loop\n",
    "    smoothed_hists = {s: gaussian_filter1d(hist, sigma=s) for s in smooth_range}\n",
    "\n",
    "    for smooth_val in smooth_range:\n",
    "        current_hist = smoothed_hists[smooth_val]\n",
    "        max_h = current_hist.max()\n",
    "        \n",
    "        for min_dist, prom in itertools.product(min_dist_range, prominence_range):\n",
    "            prom_thresh = max_h * prom\n",
    "            \n",
    "            # Find threshold based on peakiness\n",
    "            T, p_score = threshold_peakiness_advanced(current_hist, min_dist, prom_thresh)\n",
    "            \n",
    "            # Generate binary for scoring\n",
    "            binary = (image >= T).astype(np.uint8) * 255\n",
    "            \n",
    "            # Evaluate\n",
    "            score = segmentation_score(image, binary, T, p_score, edges, hist)\n",
    "\n",
    "            if score > best_global_score:\n",
    "                best_global_score = score\n",
    "                best_results = {\n",
    "                    \"params\": (min_dist, prom, smooth_val),\n",
    "                    \"threshold\": T,\n",
    "                    \"binary\": binary,\n",
    "                    \"score\": score\n",
    "                }\n",
    "\n",
    "    return best_results\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Execution\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    img = load_and_preprocess(\"test1.img\")\n",
    "    \n",
    "    if img is not None:\n",
    "        result = optimize_segmentation(img)\n",
    "        \n",
    "        print(f\"Optimal Threshold: {result['threshold']}\")\n",
    "        print(f\"Confidence Score: {result['score']:.4f}\")\n",
    "        print(f\"Params (Dist, Prom, Smooth): {result['params']}\")\n",
    "        \n",
    "        cv2.imwrite(\"optimized_result.png\", result['binary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
