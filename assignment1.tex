\documentclass[11pt, letterpaper]{article}

% --- Encoding & Margins ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{framed}

\geometry{margin=1in}

% --- Fonts ---
\usepackage{mathptmx} % Times New Roman
\usepackage[scaled]{helvet} 
\usepackage{courier}

% --- Graphics & Tables ---
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{array}

% --- Math ---
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% --- Code Highlighting ---
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\colorlet{shadecolor}{orange!15}
\lstset{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=Python
}

% --- Links & Headers ---
\usepackage{hyperref}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{CSCI 8820: Assignment 1}
\renewcommand{\headrulewidth}{0.5pt}

% ============================================================
% DOCUMENT START
% ============================================================
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{2in}
    {\huge \bfseries Assignment 1: Connected Component Labeling and Analysis \par}
    \vspace{0.6in}
    {\Large name \par}
    {\large UGA ID: 811xxxx \par}
    \vspace{0.6in}
    {\large CSCI 8820: Computer Vision and Pattern Recognition \par}
    {\large Department of Computer Science, University of Georgia \par}
    {\large February 12, 2026 \par}
\end{titlepage}

\newpage
\tableofcontents
\newpage

\section{Introduction and Preprocessing}
This report implements an iterative Connected Component Labeling (CCL) algorithm to segment and analyze objects in a grayscale image. The pipeline involves binary thresholding, labeling, and geometric feature extraction.

\subsection{Thresholding and Binary Mask Generation}
The input image $B$ was converted to a binary image $B_T$ using a fixed threshold $T=128$. To ensure consistency, the mask was automatically inverted by $B_{T} = 1-B_{T}$.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Image_B_Original.png}
        \caption{Original Grayscale Image ($B$)}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Image_BT_Binary.png}
        \caption{Thresholded Binary Image (with inversion) ($B_T$)}
    \end{subfigure}
    \caption{Preprocessing: Conversion from 8-bit grayscale to binary mask.}
\end{figure}

\section{Methodology}
\subsection{Connected Component Labeling (CCL)}
An iterative 4-connected CCL algorithm was implemented using a two-pass approach:
\begin{enumerate}
    \item \textbf{First Pass:} Raster-scanning the image and assigning temporary labels based on the 4 connectivity of the top and left neighbors. Collisions were managed via a union-find data structure.
    \item \textbf{Second Pass:} Resolution of equivalences to merge components and sequential re-labeling of the final IDs.
\end{enumerate}
% \newpage
\subsection{Feature Extraction and Mathematical Models}

Geometric properties were derived from the zeroth-, first-, and second-order central moments.

\begin{itemize}

\item \textbf{Area and Centroid:}  
The area and centroid coordinates of a binary object $B(i,j)$ are defined as

\begin{align}
A &= \sum_{i=1}^{n} \sum_{j=1}^{m} B(i, j), \\
X_c &= \frac{1}{A} \sum_{i=1}^{n} \sum_{j=1}^{m} j \, B(i,j), \\
Y_c &= \frac{1}{A} \sum_{i=1}^{n} \sum_{j=1}^{m} i \, B(i,j),
\end{align}

where $A$ denotes the object area, and $(X_c, Y_c)$ represents the centroid location.

\item \textbf{Orientation ($\theta$):}  
The principal axis orientation is obtained by minimizing the second central moment:

\begin{equation}
\theta = \frac{1}{2} \tan^{-1}\!\left( \frac{b}{a - c} \right),
\end{equation}

where $a$, $b$, and $c$ are second-order central moments.

\item \textbf{Second-Order Central Moments:}  
These moments are computed as

% \begin{shaded}
\begin{align}
a &= \sum_{i=1}^{n} \sum_{j=1}^{m} [X'(i,j)]^2 \, B(i,j), \\
b &= 2 \sum_{i=1}^{n} \sum_{j=1}^{m} X'(i,j) Y'(i,j) \, B(i,j), \\
c &= \sum_{i=1}^{n} \sum_{j=1}^{m} [Y'(i,j)]^2 \, B(i,j),
\end{align}
% \end{shaded}

where $X'(i,j) = j - X_c$ and $Y'(i,j) = i - Y_c$ denote centroid-shifted coordinates.

\item \textbf{Eccentricity:}  
The eccentricity of the object is computed from the eigenvalues of the covariance matrix:

\begin{equation}
\text{Eccentricity} = \sqrt{1 - \frac{I_{\min}}{I_{\max}}},
\end{equation}

where $I_{\max}$ and $I_{\min}$ are the major and minor principal moments, respectively.
\begin{shaded}
\textbf{\textit{Note:}} Consistency of the moment calculations was verified by checking that the invariant relation $\vert (a + c) - (I_{\max} + I_{\min}) \vert$ remained close to zero. With a maximum absolute error of 
$6.0 \times 10^{-8}$ across all tests.
\end{shaded}


\item \textbf{Compactness:}  
Compactness, a measure of shape circularity, is defined as

\begin{equation}
\text{Compactness} = \frac{P^2}{A},
\end{equation}

where $P$ is the perimeter and $A$ is the area.

\end{itemize}


\section{Experimental Results}
The algorithm was evaluated across three minimum size thresholds: 100, 500, and 1000 pixels.\\
\textbf{\textit{Note:}} Kindly correlate the Labeled Components in Figure 2, Figure 4 and Figure 6 with Component Description Table Figure 3, Figure 5 and Figure 7 respectively.

\subsection{Case 1: Minimum Size Threshold = 100}
At $T_{size}=100$, the algorithm labels artifacts/noise in the image as components along with primary objects of interest as shown in $Figure \ 2$.

\begin{figure}[H]
    \centering
    % Labeled Components Image
    \includegraphics[width=0.7\textwidth]{Image_C_Size_100.png}
    \vspace{0.3cm} % small gap
    % Table
    \includegraphics[width=0.9\textwidth]{Component_Description_Table_Size_100.pdf}
    \caption{Labeled Components and Corresponding Feature Table for Case 1}
\end{figure}

\subsection{Case 2: Minimum Size Threshold = 500}
Increasing the threshold effectively filters out noise while correctly labelling the primary objects.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{Image_C_Size_500.png}
    \caption{Labeled Components ($Size \ge 500$).}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Component_Description_Table_Size_500.pdf}
    \caption{Extracted Features for Case 2 .}
\end{figure}

\subsection{Case 3: Minimum Size Threshold = 1000}
At $T_{size}=1000$, leaves only the most significant geometric structures.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{Image_C_Size_1000.png}
    \caption{Labeled Components ($Size \ge 1000$).}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Component_Description_Table_Size_1000.pdf}
    \caption{Extracted Features for Case 3 .}
\end{figure}

\section{Discussion and Analysis}
\subsection{Noise Analysis and Size Filter Trade-off}
The experimental results highlight a fundamental trade-off:
\begin{itemize}
    \item \textbf{Lower Threshold (100 \& 500):} Small noise components are detected as objects.
    \item \textbf{High Threshold (1000):} Fine structural details may be lost if they do not meet the pixel count $(T_{size})$ requirement.
\end{itemize}

\subsection{Geometric Validation}
To ensure the accuracy of the moment-based orientation, the invariant property $I_{max} + I_{min} = a + c$ was calculated. The error was consistently negligible ($6.0\times10^{-8}$), validating the orientation calculation and axis visualization.

\section{Conclusion}
The iterative CCL algorithm effectively labelled the components in the test image.

\begin{shaded}
\textbf{\textit{Note:}} For source code kindly refer to appendix at the end.
\end{shaded}

\newpage
\section*{Appendix: Source Code}
The following Python script was used to perform all operations described in this report.

\begin{lstlisting}
# Paste your python code here. 
# It will be formatted automatically with syntax highlighting.
\end{lstlisting}

\end{document}